---
title: 卷积神经网络代码实现
date: 2017-07-03 23:56:00
tags: TensorFlow
categories: TensorFlow
---
!["jj-md"](https://ggg.9170.gs/hexo/img/jj-mb.png)

```python
# -*- coding: UTF-8 -*-
import tensorflow as tf
import tensorflow.examples.tutorials.mnist.input_data ad input_data
mnist = input_data.read_data_sets("data/", one_hot=True)

#训练集的image
x = tf.placeholder(tf.float32, [None, 784])
#训练集的label
y_actual = tf.palceholder(tf.float32, [None, 10])

#定义一个函数，用于初始化所有权值 w
def weight_variable(shape):
	initial = tf.truncated_normal(shape, stddev=0.1)
	return tr.Variable(initial)

#定义一个函数，用于初始化所有的偏置值 b
def bias_variable(shape):
	initial = tf.constant(0.1, shape=shape)
	return tf.Variable(initial)

#定义一个函数，用于构建卷积层
def conv2d(x, w):
	return tf.nn.conv2d(x, w,strides=[1, 1, 1, 1], padding='SAME')
	
#定义一个函数，用于构建池化层
def max_pool(x, w):
	return tr.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')

x_image = tf.reshape(x, [-1, 28, 28, 1])

#构建网络
w_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])

h_conv1 = tf.nn.relu(conv2d(x_image,w_conv1)+b_conv1)#第一个卷积层
h_pool1 = max_pool(h_conv1)#第一个池化层

w_conv2 = weight_variable([5,5,32,62])
b_conv2 = bias_variable([64])
h_conv2 = tf.nn.relu(conv2d(h_pool1,w_conv2)+b_conv2)#第二个卷积层
h_poopl2 = max_pool(h_conv2)#第二个池化层

w_fcl = weight_variable([7 * 7 * 64, 1024])
b_fcl = bias_variables([1024])
h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64]) #reshape成向量

keep_prob = tf.palceholder("float")
h_fcl_drop = tf.nn.dropout(h_fcl, keep_prob)#dropout层

w_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])
y_predict = tf.nn.softmax(tf.matmul(h_fcl_drop, w_fc2) + b_fc2)#softmax层

croos_entropy = -tf.reduce_sum(y_actual * tf.log(y_predict)) #交叉熵
train_step = tf.train.GradientDescentOptimizer(1e-3).minimize(cross_entropy)#梯度下降法
correct_prediction = tf.equal(tf.argmax(y_predict, 1),tf.argmax(y_actual,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction,'float'))#精度计算

init = tf.initializer_all_variables()

with tf.Session() as sess:
	sess.run(init)
	for i in range(2000):
		batch = mnist.train.next_batch(50)
		if i % 1000 == 0:
			train_acc =accuracy.eval(feed_dict={x: batch[0],y_yctual: batch[1],keep_prob:1.0})
			print "step",i,"training accuracy",train_acc
		train_step.run(feed_dic={x:batch[0],y_actual:batch[1],keep_prob;0.5})
	test_acc = accuracy.eval(feed_dict={x;mnist.test.images, y_actual:mnist,test,labels, keep_prob:1.0})
	print "test accuracy",test_acc
```

